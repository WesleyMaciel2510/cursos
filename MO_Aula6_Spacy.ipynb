{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MO.Aula6.Spacy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNI5KwR4Jpxjlkea4puYfLj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmelo-uea/cursos/blob/main/MO_Aula6_Spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TorwSQBy8KZ5"
      },
      "source": [
        "#spaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC5aSIiJ8ReW"
      },
      "source": [
        "## Características:\n",
        "\n",
        "*   **spaCy** é uma das mais populares bibliotecas de NLP (*Natural Language Processing*).\n",
        "* Tem suporte para mais de 64 idiomas (incluindo **Português**).  \n",
        "* Os modelos podem customizados ou criados a partir do zero usando PyTorch, TensorFlow e/ou outras arquiteturas.\n",
        "* Recursos visuais de análise de dados.\n",
        "* Versão atual: v3.0.\n",
        "* URL: [LINK](https://spacy.io)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3l2vxJ6896Ug"
      },
      "source": [
        "## Componentes:\n",
        "\n",
        "*   Reconhecimento de entidade nomeada (*Named Entity Recognition* - NER).\n",
        "*   *Part-of-speech tagging* (POS).\n",
        "*   Árvore de dependência (*dependency parsing*).\n",
        "*   Segmentação de sentenças.\n",
        "*   Classificação de texto.\n",
        "*   *Lemmatization*.\n",
        "*   ...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idTgLXAo_kef"
      },
      "source": [
        "# Instalação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzO1aINO_nnL"
      },
      "source": [
        "Se você for usuário de ```pip``` para instalar as bibliotecas Python, então basta executar o seguinte comando:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grJ2rU8sAFep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fff20ae-7d06-4cc9-e569-0ac3ad1b4cb7"
      },
      "source": [
        "!pip install -U spacy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/d8/0361bbaf7a1ff56b44dca04dace54c82d63dad7475b7d25ea1baefafafb2/spacy-3.0.6-cp37-cp37m-manylinux2014_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 281kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Collecting pathy>=0.3.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/87/5991d87be8ed60beb172b4062dbafef18b32fa559635a8e2b633c2974f85/pathy-0.5.2-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n",
            "\u001b[?25hCollecting thinc<8.1.0,>=8.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/87/decceba68a0c6ca356ddcb6aea8b2500e71d9bc187f148aae19b747b7d3c/thinc-8.0.3-cp37-cp37m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 37.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Collecting typer<0.4.0,>=0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/67/d4002a18e26bf29b17ab563ddb55232b445ab6a02f97bf17d1345ff34d3f/spacy_legacy-3.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Collecting pydantic<1.8.0,>=1.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/fa/d43f31874e1f2a9633e4c025be310f2ce7a8350017579e9e837a62630a7e/pydantic-1.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.1MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1MB 35.1MB/s \n",
            "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/10/dbc1203a4b1367c7b02fddf08cb2981d9aa3e688d398f587cea0ab9e3bec/catalogue-2.0.4-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (20.9)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/84/dfdfc9f6f04f6b88207d96d9520b911e5fec0c67ff47a0dea31ab5429a1e/srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 40.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (56.1.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n",
            "Collecting smart-open<4.0.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/9a/ba2d5f67f25e8d5bbf2fcec7a99b1e38428e83cb715f64dd179ca43a11bb/smart_open-3.0.0.tar.gz (113kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 44.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Collecting click<7.2.0,>=7.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl (82kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n",
            "Building wheels for collected packages: smart-open\n",
            "  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for smart-open: filename=smart_open-3.0.0-cp37-none-any.whl size=107098 sha256=207c8e9393f2a9c9b867b818b2d5bfac0feba3452c213c4f83bb36ca67c64d9d\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/88/7c/f06dabd5e9cabe02d2269167bcacbbf9b47d0c0ff7d6ebcb78\n",
            "Successfully built smart-open\n",
            "Installing collected packages: click, typer, smart-open, pathy, pydantic, catalogue, srsly, thinc, spacy-legacy, spacy\n",
            "  Found existing installation: click 8.0.0\n",
            "    Uninstalling click-8.0.0:\n",
            "      Successfully uninstalled click-8.0.0\n",
            "  Found existing installation: smart-open 5.0.0\n",
            "    Uninstalling smart-open-5.0.0:\n",
            "      Successfully uninstalled smart-open-5.0.0\n",
            "  Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.4 click-7.1.2 pathy-0.5.2 pydantic-1.7.4 smart-open-3.0.0 spacy-3.0.6 spacy-legacy-3.0.5 srsly-2.4.1 thinc-8.0.3 typer-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0VYT2EyAlMG"
      },
      "source": [
        "Caso você esteja usando **Anaconda**, você pode usar o seguinte comando:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABX6twT-AsBC"
      },
      "source": [
        "```\n",
        "$ conda install -c conda-forge spacy\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6Zn7JX4A2ud"
      },
      "source": [
        "Após você instalar o spaCy, será necessário fazer o download do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUA86RyOBJbC"
      },
      "source": [
        "Os modelos estão disponíveis por idioma."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmvaMLz1BTAs"
      },
      "source": [
        "O seguinte comando permite fazer o download do modelo (inglês):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sshvxabKBXnS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a404315-5838-4af9-ab91-58a7e307a2b7"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-19 17:26:28.791191: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Collecting en-core-web-sm==3.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7MB)\n",
            "\u001b[K     |████████████████████████████████| 13.7MB 299kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.0.0) (3.0.6)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (56.1.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.3)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.5.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.9)\n",
            "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.4.1)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.0)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "Successfully installed en-core-web-sm-3.0.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6FVWsnqBhrl"
      },
      "source": [
        "# Funcionalidades Básicas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWgtPwC1B1kG"
      },
      "source": [
        "O primeiro passo é importar a biblioteca."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KAn6tMHB5zq"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaJYhm1cCBBk"
      },
      "source": [
        "O segundo passo é carregar o modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQiERH9kCEJR"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QZFV2pwXK6g"
      },
      "source": [
        "Os nomes dos pacotes (modelos) do spaCy seguem uma convenção.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LUpXgFLYj7t"
      },
      "source": [
        "Os nomes iniciam com `[lang]_[name]` acompanhados por três partes:\n",
        "\n",
        "1.   **Tipo**: `core` para uso geral (vocabulário, sintaxe, entidades etc) ou `dep` somente para vocabulário e sintaxe. \n",
        "\n",
        "2.   **Fonte**: O tipo de texto que o modelo foi treinado (`web` ou `news`).\n",
        "\n",
        "3.   **Tamanho**: Tamanho do pacote (`sm`, `md` ou `lg`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LfwXOBPYQ6W"
      },
      "source": [
        "Por exemplo, o pacote `en_core_web_sm` é um pequeno modelo em inglês treinado com texto da Web."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1fDUDg98qG4"
      },
      "source": [
        "Avaliação do Modelo:\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=12chtMFnRG48gVkBRUe2WPWYmOIOgpd1o'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j00Kq9JLD2FU"
      },
      "source": [
        "# Tokenização"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKg5atnQEKeY"
      },
      "source": [
        "É o processo de separar as palavras (termos), símbolos e pontuações de um texto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq_EY6g4EdfJ"
      },
      "source": [
        "Considere o exemplo de uma sentença abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEvvxiOMCcLV"
      },
      "source": [
        "texto = \"The battery life of S-10 is excellent.\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k12Afgu6DEsz"
      },
      "source": [
        "doc = nlp (texto)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkI0wW8qEsWT",
        "outputId": "d772c93a-6acb-4bd7-9ca2-67a68265f707"
      },
      "source": [
        "for termo in doc:\n",
        "  print (termo)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The\n",
            "battery\n",
            "life\n",
            "of\n",
            "S-10\n",
            "is\n",
            "excellent\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AdUuGyWE9wG"
      },
      "source": [
        "# Manipulação de Documentos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlHetyHg6S__"
      },
      "source": [
        "Em geral, os textos (documentos) são formados de parágrafos e estes são formados por sentenças."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zKbXhUW6Z9U"
      },
      "source": [
        "Um passo comumente necessário é dividir os textos em sentenças."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUjHb9KcF_2Y"
      },
      "source": [
        "texto = \"I received my phone in 2.5 days! For the price you can't beat it. I have zero complaints. The phone is brand new and no signs of wear. Super clear screen and battery life is good. I have metro pcs and it was very easy to set it up with customer service.\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PIfMoG0Ga8Y"
      },
      "source": [
        "doc = nlp (texto)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGd_bAlUGYf8"
      },
      "source": [
        "É possível separar o texto em sentenças:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsyAkEJhGhm5",
        "outputId": "396756c3-33ab-4974-c38d-b83f7fc2e93a"
      },
      "source": [
        "for i in doc.sents:\n",
        "  print (i)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I received my phone in 2.5 days!\n",
            "For the price you can't beat it.\n",
            "I have zero complaints.\n",
            "The phone is brand new and no signs of wear.\n",
            "Super clear screen and battery life is good.\n",
            "I have metro pcs and it was very easy to set it up with customer service.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVzUqQ9MGw5H"
      },
      "source": [
        "Deve-se observar que o modelo foi capaz de identificar que o ponto em 2.5 não representava o término da sentença."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PORpOKTaHjig"
      },
      "source": [
        "# POS *tagging*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7h96YepDKWJR"
      },
      "source": [
        "É possível identificar diversas características dos termos que compõem uma sentença."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q3cXQyCI9Wi"
      },
      "source": [
        "Características comumente utilizadas em problemas de NLP:\n",
        "\n",
        "* `Text`: Palavra original do texto.\n",
        "\n",
        "* `Lemma`: A forma base do termo.\n",
        "\n",
        "* `POS`: POS tag do termo.\n",
        "\n",
        "* `Tag`: POS tag detalhada.\n",
        "\n",
        "* `Dep`: Dependência sintática entre os termos.\n",
        "\n",
        "* `is alpha`: Verifica se o termo é formado exclusivamente por caracteres.\n",
        "\n",
        "* `is stop`: Verifica se o termo é um *stopword* (termo comum)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iGzYvdyIJ5Z",
        "outputId": "d25c48d1-60a1-4b1b-c884-f6a6ca560312"
      },
      "source": [
        "doc = nlp(\"The battery life is fantastic.\")\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_, token.is_alpha, token.is_stop)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The the DET DT det True True\n",
            "battery battery NOUN NN compound True False\n",
            "life life NOUN NN nsubj True False\n",
            "is be AUX VBZ ROOT True True\n",
            "fantastic fantastic ADJ JJ acomp True False\n",
            ". . PUNCT . punct False False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QQKt7TrQl13"
      },
      "source": [
        "# Árvore de Dependência (*Dependency Parsing*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m339kqY_Qq7g"
      },
      "source": [
        "É o processo de analisar a estrutura gramatical de uma sentença baseada nas dependências entre os termos em uma sentença."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lao3MtCqTO74"
      },
      "source": [
        "Caracaterísticas utilizadas em problemas de NLP:\n",
        "\n",
        "`Text`: O termo original do texto.\n",
        "\n",
        "`Dep`: A relação sintática entre dois termos (child -> head).\n",
        "\n",
        "`Head text`: O texto original do termo (*head*).\n",
        "\n",
        "`Head POS`: O POS tag do *head*.\n",
        "\n",
        "`Children`: O texto original do termo (*child*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZlEhdp8RK75",
        "outputId": "df1e8081-d84f-465c-b5ab-a3e01b26009e"
      },
      "source": [
        "doc = nlp(\"The battery life is fantastic and also expensive.\")\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
        "            [child for child in token.children])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The det life NOUN []\n",
            "battery compound life NOUN []\n",
            "life nsubj is AUX [The, battery]\n",
            "is ROOT is AUX [life, fantastic, .]\n",
            "fantastic acomp is AUX [and, expensive]\n",
            "and cc fantastic ADJ []\n",
            "also advmod expensive ADJ []\n",
            "expensive conj fantastic ADJ [also]\n",
            ". punct is AUX []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uqxaANZN6PF"
      },
      "source": [
        "# Lemmatization e Stemming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEAxFMKjHcIE"
      },
      "source": [
        "Em muitas situações, é necessário aplicar técnicas para reduzir as formas flexionadas de uma palavra para uma forma básica comum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWtkn89YIv-a"
      },
      "source": [
        "**Lemmatization** e **stemming** são as duas técnicas comumente utilizadas para tal redução."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeKy-VRhJtO3"
      },
      "source": [
        "## Lemmatization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzIDzKnVN8EH"
      },
      "source": [
        "*Lemmatization* é o processo de agrupar formas flexionadas de uma palavra para que possam ser analisadas como um único termo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nsPVshKJHUL"
      },
      "source": [
        "Exemplo: *run*, *runs* e *running* poderiam ser representada apenas como *run*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa55DkZcJqVO"
      },
      "source": [
        "O processo de *lemmatization* transforma o contexto e converte para a sua forma base (*lemma*) e que aparece em um dicionário."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbbZhA2aO9PX",
        "outputId": "569827d0-7dbb-4c52-fa64-38f646a78a40"
      },
      "source": [
        "lemmatizer = nlp.get_pipe(\"lemmatizer\") \n",
        "\n",
        "doc = nlp(\"go goes going went gone\")\n",
        "\n",
        "print([token.lemma_ for token in doc])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['go', 'go', 'go', 'go', 'go']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MMBpXe4KU8-"
      },
      "source": [
        "## Stemming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agQ6QwZqKmyD"
      },
      "source": [
        "Stemming é o processo de cortar o prefixo e/ou sufixo das palavras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpMazLI4KyIz"
      },
      "source": [
        "O corte indiscriminado das palavras pode gerar termos que não são palavras existentes em um dicionário."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s7WRHbKL3i_"
      },
      "source": [
        "O spaCy **não** implementa algoritmos de stemming."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6k-P26HMJIO"
      },
      "source": [
        "Uma alternativa seria usar uma outra biblioteca: [NLTK](https://www.nltk.org/howto/stem.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpQ9Bc02Mgmu"
      },
      "source": [
        "Importar a bilioteca:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk6uGV4GMX3D"
      },
      "source": [
        "import nltk\n",
        "\n",
        "from nltk.stem.porter import *"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUgYdO12MlBp"
      },
      "source": [
        "Criar um objeto a partir da classe Porter:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zT6ui2fMi5w"
      },
      "source": [
        "stemmer = PorterStemmer()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jpw_mEzLMvQb"
      },
      "source": [
        "Exemplos 1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHYCm7faMrqM",
        "outputId": "3ab22235-5fad-4670-a509-d0b9542ec44f"
      },
      "source": [
        "tokens = ['compute', 'computer', 'computed', 'computing']\n",
        "\n",
        "for token in tokens:\n",
        "    print(token + ' --> ' + stemmer.stem(token))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compute --> comput\n",
            "computer --> comput\n",
            "computed --> comput\n",
            "computing --> comput\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSuvNHhQMzoa"
      },
      "source": [
        "Exemplos 2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8Zwd6wjM2RE",
        "outputId": "fac2071e-906c-4a3f-c5d9-800314fe1f20"
      },
      "source": [
        "tokens = ['go', 'goes', 'going', 'went', 'gone']\n",
        "\n",
        "for token in tokens:\n",
        "    print(token + ' --> ' + stemmer.stem(token))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "go --> go\n",
            "goes --> goe\n",
            "going --> go\n",
            "went --> went\n",
            "gone --> gone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7Lh_bAxURz9"
      },
      "source": [
        "# Reconhecimento de Entidades Nomeadas (NER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPx9RFWiUaxx"
      },
      "source": [
        "Uma entidade nomeada (*named entity*) é um objeto do mundo real que pode ter assinalado um nome."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd-JJfBzNNRL"
      },
      "source": [
        "Uma entidade pode ser uma pessoa, país, produto ou título de livro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqEu1cehNPOl"
      },
      "source": [
        "Os modelos do spaCy são capazes de reconhecer vários tipos de entidades nomeadas em um documento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDPdAftRNRsJ"
      },
      "source": [
        "As entidades nomeadas estão disponíveis como proporiedade `ents` de objetos `Docs` do spaCy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWXDkam7NYQi"
      },
      "source": [
        "Exemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DnDRznqNVwz"
      },
      "source": [
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xms61T8WU9nb",
        "outputId": "6ce92477-ad42-40eb-d6f9-ce5ab2297d9e"
      },
      "source": [
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple 0 5 ORG\n",
            "U.K. 27 31 GPE\n",
            "$1 billion 44 54 MONEY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8M7iDDxU8eJ"
      },
      "source": [
        "Deve-se observar que *Apple* foi identificado como uma ORG!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMZx1Xp8LCOF"
      },
      "source": [
        "# Visualizador displaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JohFn3wfLJ-F"
      },
      "source": [
        "O spaCy possui uma biblioteca que permite visualizar as dependências entre os termos de uma sentença."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icAhjQaZLUlX"
      },
      "source": [
        "from spacy import displacy"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wtc4dCE6L_mT"
      },
      "source": [
        "A biblioteca pode ser utilizada através do seguinte comando: \n",
        "\n",
        "`displacy.serve(doc, style=\"dep\")`\n",
        "\n",
        "Para exibição em um notebook (COLAB ou jupyter), deve-se adaptar uma renderização. A seguir, é apresentado um exemplo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "xar9lpT7LXiH",
        "outputId": "e50483ac-9184-4583-8f06-a572257a8d45"
      },
      "source": [
        "doc = nlp(\"The battery life is fantastic.\")\n",
        "displacy.render(doc, style='dep', jupyter=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"be1a009093da46c8bb4470519818687f-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">battery</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">life</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">fantastic.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-be1a009093da46c8bb4470519818687f-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-be1a009093da46c8bb4470519818687f-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-be1a009093da46c8bb4470519818687f-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-be1a009093da46c8bb4470519818687f-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-be1a009093da46c8bb4470519818687f-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-be1a009093da46c8bb4470519818687f-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-be1a009093da46c8bb4470519818687f-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-be1a009093da46c8bb4470519818687f-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOfu8F8CVl0o"
      },
      "source": [
        "O **displaCy** permite também a visualização de NER."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "cPxb8iDjVsse",
        "outputId": "78e75134-33f5-4c07-cc5f-af11e599d245"
      },
      "source": [
        "text = \"Apple is looking at buying U.K. startup for $1 billion.\"\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(text)\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is looking at buying \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    U.K.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " startup for \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    $1 billion\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              ".</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6DwtgQFZeps"
      },
      "source": [
        "#spaCy em Português"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7Yazpc2aoFj"
      },
      "source": [
        "Vamos executar o parser do modelo em inglês para uma sentença em português e observar o resultado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaIRT50VaNju",
        "outputId": "d14b920f-928e-4b27-e911-e80a5d53fbe6"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"O celular é muito bom.\")\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_, token.is_alpha, token.is_stop)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O o INTJ UH intj True False\n",
            "celular celular NOUN NN ROOT True False\n",
            "é é DET DT det True False\n",
            "muito muito NOUN NN compound True False\n",
            "bom bom NOUN NN npadvmod True False\n",
            ". . PUNCT . punct False False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU9IwlVDa8ll"
      },
      "source": [
        "Um aspecto positivo do spaCy é a possibilidade de usar modelos prontos em vários idiomas e também a facilidade de se construir modelos próprios (customizados)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkZJz6hGbTtl"
      },
      "source": [
        "Vamos instalar o pacote `pt_core_news_sm`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtGur3qXbURq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da677cd7-b090-4c64-a38f-e1e96c86ca11"
      },
      "source": [
        "!python -m spacy download pt_core_news_sm"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-19 17:42:47.195535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Collecting pt-core-news-sm==3.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.0.0/pt_core_news_sm-3.0.0-py3-none-any.whl (22.1MB)\n",
            "\u001b[K     |████████████████████████████████| 22.1MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from pt-core-news-sm==3.0.0) (3.0.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (20.9)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (1.7.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (56.1.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2.0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (1.0.5)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (8.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (0.5.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (3.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2.0.0)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (3.0.0)\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.0.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Eb7a0pqbvBN"
      },
      "source": [
        "Importar o pacote para português:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeayYJubbsM8"
      },
      "source": [
        "import pt_core_news_sm"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEmj0q_GOWBO"
      },
      "source": [
        "Execução para um texto em Portugue (BR):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jul27S9mbhXx",
        "outputId": "9c64b06d-8e0f-4061-a33e-3abd4e1477e5"
      },
      "source": [
        "nlp = pt_core_news_sm.load()\n",
        "sentence = \"O celular é muito bom.\"\n",
        "doc = nlp(sentence)\n",
        "for token in doc:\n",
        "    print(token.text, token.tag_, token.head.text, token.dep_, token.pos_)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O DET celular det DET\n",
            "celular NOUN bom nsubj NOUN\n",
            "é AUX bom cop AUX\n",
            "muito ADV bom advmod ADV\n",
            "bom ADJ bom ROOT ADJ\n",
            ". PUNCT bom punct PUNCT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep-g6TmeZGw2"
      },
      "source": [
        "# Exercícios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jMpUvgLK8ZJ"
      },
      "source": [
        "Qual é a diferença entre *lemmatization* e *stemming*? Dê um exemplo de cada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpUj_95MZKIo"
      },
      "source": [
        "Implementar um conjunto de regras para extração de aspectos.\n",
        "\n",
        "Considere o artigo \"*Explicit aspects extraction in sentiment analysis using optimal rules combination*\" [[1](https://www.sciencedirect.com/science/article/pii/S0167739X1933081X)]. Escolha e implemente cinco regras que aparecem nas tabelas 3, 4 e 5 do artigo e avalie o resultado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XGd_sDQOzP_"
      },
      "source": [
        "Explore a criação de modelos próprios usando o spaCy [[Link](https://spacy.io/usage/training)]."
      ]
    }
  ]
}